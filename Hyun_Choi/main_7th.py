import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
from sklearn.utils.class_weight import compute_class_weight
import os
from datetime import datetime
from pathlib import Path
from PIL import Image
import urllib.request
import glob
import warnings
import wandb
import random
from torch.optim.lr_scheduler import LambdaLR
import math 
import copy 

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
warnings.filterwarnings("ignore", category=UserWarning)

# ==============================================================================
# 0. EMA (Exponential Moving Average) ëª¨ë¸ ì •ì˜
# ==============================================================================
class EMAModel:
    """EMA (ì§€ìˆ˜ ì´ë™ í‰ê· ) ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤"""
    def __init__(self, model, decay):
        self.model = model
        self.decay = decay
        self.shadow = copy.deepcopy(model.state_dict())
        self.steps = 0

    def update(self):
        """ë§¤ Stepë§ˆë‹¤ ì´ë™ í‰ê·  ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        self.steps += 1
        # Cosine EMA Decay ì ìš©
        decay = min(self.decay, (1 + self.steps) / (10 + self.steps)) 
        
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]
                self.shadow[name] = new_average.clone()
        
    def apply_shadow(self, save_path=None):
        """ì €ì¥ ë˜ëŠ” ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì— EMA ê°€ì¤‘ì¹˜ ì ìš©"""
        original_state_dict = self.model.state_dict()
        self.model.load_state_dict(self.shadow)
        
        if save_path:
            torch.save(self.model.state_dict(), save_path)
        
        self.model.load_state_dict(original_state_dict)


# ==============================================================================
# 1. ì„¤ì • ë° í™˜ê²½ (ì‹œê°„ ë‹¨ì¶• ë° ì¼ë°˜í™” ê°œì„ )
# ==============================================================================
# ğŸš¨ Augraphy ì œê±° (ì¼ë°˜í™” ì‹¤íŒ¨ì˜ ì£¼ìš” ì›ì¸ìœ¼ë¡œ íŒë‹¨)
AUGRAPHY_AVAILABLE = False
# print("âš ï¸ Augraphy ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì„ ì¤‘ì§€í•©ë‹ˆë‹¤. (ì¼ë°˜í™” ê°œì„  ëª©ì )")

class Config:
    """ìµœì¢… ìš°ìŠ¹ì„ ìœ„í•œ ì„¤ì • (ConvNeXt + EMA + TTA + PL Gap Fix)"""
    PROJECT_NAME = "document-classification-v7"
    RUN_NAME = "ConvNeXt_EMA_PL_FIX_Refined_V9"
    
    MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k' 
    NUM_CLASSES = 17
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Mixup/CutMix í™•ë¥  ê°ì†Œ (ê³¼ì í•© ë°©ì§€)
    USE_MIX_STRATEGY = True
    MIXUP_ALPHA = 0.4
    CUTMIX_ALPHA = 1.0 
    MIX_PROB = 0.5 # ğŸ”¥ ê¸°ì¡´ 0.8 -> 0.5ë¡œ ê°ì†Œ
    
    # ğŸ”¥ EMA Decay ì¡°ì • (ê°€ì¤‘ì¹˜ ë³€í™” ì†ë„ ì•½ê°„ ì¦ê°€ -> ëœ ê³µê²©ì ì¸ ì •ê·œí™”)
    EMA_DECAY = 0.999 
    
    # ğŸ”¥ ì‹¤í—˜ ì‹œê°„ ë‹¨ì¶•: Epoch ê°ì†Œ
    N_EPOCHS = 30 # ê¸°ì¡´ 50 -> 30ìœ¼ë¡œ ê°ì†Œ
    
    # ğŸ”¥ ì‹¤í—˜ ì‹œê°„ ë‹¨ì¶• ë° OOM ì™„í™”: BATCH_SIZE ì¡°ì •
    BATCH_SIZE = 16  # ê¸°ì¡´ OOM í”½ìŠ¤ 8 -> 16ìœ¼ë¡œ ì¦ê°€ (ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸ í›„)
    IMAGE_SIZE = 384  
    
    # ğŸ”¥ ì‹¤í—˜ ì‹œê°„ ë‹¨ì¶•: Accumulation Steps ì¡°ì • (Effective Batch Size 32 ìœ ì§€)
    GRADIENT_ACCUMULATION_STEPS = 2 # ê¸°ì¡´ OOM í”½ìŠ¤ 4 -> 2ë¡œ ê°ì†Œ (BATCH_SIZE 16ì— ë§ì¶¤)
    
    # ìµœì í™”
    LR = 1e-4 
    WARMUP_EPOCHS = 3 # Warmupë„ 5->3ìœ¼ë¡œ ì•½ê°„ ê°ì†Œ
    
    # K-Fold ë° ì •ì§€
    N_FOLDS = 5 
    WEIGHT_DECAY = 0.05
    LABEL_SMOOTHING = 0.05
    PATIENCE = 5 # ğŸ”¥ Early Stopping ë¯¼ê°ë„ ì¦ê°€ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)
    
    # ğŸ”¥ ì¶”ë¡  ì‹œê°„ ë‹¨ì¶•: TTA í¬ê¸° ê°ì†Œ
    TTA_SIZE = 3 # ê¸°ì¡´ 7 -> 3ìœ¼ë¡œ ê°ì†Œ
    
    DATA_DIR = 'data'
    ENSEMBLE_MODEL_BASE_DIR = './experiments'

# ==============================================================================
# 2. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ë° í´ë˜ìŠ¤ 
# ==============================================================================

def download_and_extract_data(data_dir='data'):
    """ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ"""
    data_path = Path(data_dir)
    if data_path.exists() and (data_path / 'train.csv').exists():
        print("âœ… ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ê±´ë„ˆê¹€.\n")
        return
    
    print("="*70)
    print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„ ì¤‘...")
    print("="*70)
    
    DATA_URL = "https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000372/data/data.tar.gz"
    DATA_FILE = "data.tar.gz"
    
    try:
        urllib.request.urlretrieve(DATA_URL, DATA_FILE)
        import tarfile
        with tarfile.open(DATA_FILE, 'r:gz') as tar:
            tar.extractall('.')
        os.remove(DATA_FILE)
        
        print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

class DocumentDataset(Dataset):
    """ë¬¸ì„œ ì´ë¯¸ì§€ ë¡œë“œ ë° ë¼ë²¨ë§ì„ ìœ„í•œ PyTorch Dataset"""
    def __init__(self, df, img_dir, transform=None, is_test=False):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_id = self.df.iloc[idx]['ID']
        img_path = os.path.join(self.img_dir, img_id)
        
        image = Image.open(img_path).convert("RGB")
        image = np.array(image)

        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']

        if self.is_test:
            return image
        else:
            label = self.df.iloc[idx]['target']
            return image, torch.tensor(label, dtype=torch.long)

def get_transforms(stage, cfg):
    """ì¼ë°˜í™” ê°œì„ ì„ ìœ„í•´ Augraphyë¥¼ ì œê±°í•˜ê³  í‘œì¤€ Augmentationë§Œ ì‚¬ìš©"""
    
    if stage == 'train':
        # ğŸ”¥ Augraphy ì œê±°. ê¸°ë³¸ì ì¸ ê°•ë ¥í•œ Augmentationë§Œ ìœ ì§€.
        albu_list = [
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), 
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.08, rotate_limit=8, p=0.7), 
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.1),
            A.OneOf([
                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),
                A.GaussNoise(var_limit=(5.0, 30.0), p=1), # ë…¸ì´ì¦ˆ ë²”ìœ„ ì™„í™”
                A.Blur(blur_limit=3, p=1), # ë¸”ëŸ¬ ë²”ìœ„ ì™„í™”
            ], p=0.6), # OneOf í™•ë¥  ê°ì†Œ
            A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.3), # Dropout ê°•ë„ ì™„í™”
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]
            
        return A.Compose(albu_list)
    
    # ğŸ”¥ ì¶”ë¡  ì‹œê°„ ë‹¨ì¶•: TTAë¥¼ ìœ„í•œ ë³€í™˜ (ë‹¨ìˆœí™”)
    elif stage == 'test': 
        return A.Compose([
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE),
            A.OneOf([
                A.HorizontalFlip(p=1.0),
                A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=1.0),
                A.JpegCompression(quality_lower=70, quality_upper=100, p=1.0), # JPEG ë…¸ì´ì¦ˆ ì™„í™”
            ], p=0.8),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    
    # Validation ë° ê¸°ë³¸ ì¶”ë¡  
    elif stage == 'val_base':
        return A.Compose([
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    
    return None

def mixup_cutmix_data(images, labels, alpha, mix_strategy='mixup'):
    """Mixup / CutMix êµ¬í˜„"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
        
    rand_index = torch.randperm(images.size(0)).to(images.device)
    mixed_images = lam * images + (1 - lam) * images[rand_index, :]

    label_a, label_b = labels, labels[rand_index]
    return mixed_images, label_a, label_b, lam


# ==============================================================================
# 3. í•™ìŠµ ë° ì¶”ë¡  ë¡œì§ (EMA í†µí•© ë° ì‹œê°„ ë‹¨ì¶•)
# ==============================================================================

def train_fold(fold, train_df, val_df, exp_dir, class_weights, cfg):
    """ë‹¨ì¼ Fold í•™ìŠµ (ì‹œê°„ ë‹¨ì¶• ë° ì¼ë°˜í™” ê°œì„ )"""
    print(f'\n{"="*50}')
    print(f'âš¡ï¸ Fold {fold} í•™ìŠµ ì‹œì‘ - Model: {cfg.MODEL_NAME}')
    print(f'   (Batch Size: {cfg.BATCH_SIZE}, Accumulation: {cfg.GRADIENT_ACCUMULATION_STEPS}, Effective: {cfg.BATCH_SIZE * cfg.GRADIENT_ACCUMULATION_STEPS})')
    print(f'   (Epochs: {cfg.N_EPOCHS}, Patience: {cfg.PATIENCE})')
    print(f'{"="*50}')
    
    run = None
    try:
        run = wandb.init(project=cfg.PROJECT_NAME, name=f"{cfg.RUN_NAME}_Fold_{fold}", config=vars(cfg), reinit=True)
    except Exception:
        print("WandB ì´ˆê¸°í™” ì‹¤íŒ¨. ë¡œê¹… ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤.")
    
    train_dataset = DocumentDataset(train_df, f'{cfg.DATA_DIR}/train', get_transforms('train', cfg))
    val_dataset = DocumentDataset(val_df, f'{cfg.DATA_DIR}/train', get_transforms('val_base', cfg))
    
    # ğŸ”¥ BATCH_SIZE 16
    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    
    model = timm.create_model(cfg.MODEL_NAME, pretrained=True, num_classes=cfg.NUM_CLASSES)
    model.to(cfg.DEVICE)
    
    ema_model = EMAModel(model, cfg.EMA_DECAY)

    criterion = nn.CrossEntropyLoss(weight=class_weights.to(cfg.DEVICE), 
                                    label_smoothing=cfg.LABEL_SMOOTHING)

    optimizer = optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)

    # Warmup + CosineAnnealing ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬í˜„
    def lr_lambda(current_step):
        if current_step < cfg.WARMUP_EPOCHS * len(train_loader):
            return float(current_step) / float(max(1, cfg.WARMUP_EPOCHS * len(train_loader)))
        T_total = cfg.N_EPOCHS * len(train_loader)
        T_rest = T_total - cfg.WARMUP_EPOCHS * len(train_loader)
        T_current = current_step - cfg.WARMUP_EPOCHS * len(train_loader)
        return 0.5 * (1. + math.cos(math.pi * T_current / T_rest))

    scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)
    
    best_f1 = 0.0
    patience_counter = 0
    model_path = os.path.join(exp_dir, f'best_model_fold_{fold}.pth')
    
    for epoch in range(cfg.N_EPOCHS):
        model.train()
        running_loss = 0.0
        train_preds_list, train_labels_list = [], []
        
        optimizer.zero_grad() 
        
        for step, (images, labels) in enumerate(tqdm(train_loader, desc=f'Fold {fold} | Epoch {epoch+1}/{cfg.N_EPOCHS} (Train)')):
            images, labels = images.to(cfg.DEVICE), labels.to(cfg.DEVICE)
            
            # ğŸ”¥ Mixup/CutMix í™•ë¥  50% ì ìš© (ê³¼ì í•© ë°©ì§€)
            if cfg.USE_MIX_STRATEGY and random.random() < cfg.MIX_PROB:
                strategy = 'mixup' if random.random() < 0.5 else 'cutmix'
                alpha = cfg.MIXUP_ALPHA if strategy == 'mixup' else cfg.CUTMIX_ALPHA
                
                mixed_images, label_a, label_b, lam = mixup_cutmix_data(images, labels, alpha, strategy)
                outputs = model(mixed_images)
                loss = lam * criterion(outputs, label_a) + (1 - lam) * criterion(outputs, label_b)
                
                preds = outputs.argmax(dim=1) 
                target_labels = label_a
            else:
                outputs = model(images)
                loss = criterion(outputs, labels)
                preds = outputs.argmax(dim=1)
                target_labels = labels
            
            loss = loss / cfg.GRADIENT_ACCUMULATION_STEPS
            loss.backward()
            
            if (step + 1) % cfg.GRADIENT_ACCUMULATION_STEPS == 0:
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad() 
                ema_model.update()
            
            running_loss += loss.item() * images.size(0) * cfg.GRADIENT_ACCUMULATION_STEPS
            train_preds_list.extend(preds.cpu().numpy())
            train_labels_list.extend(target_labels.cpu().numpy())
        
        if (step + 1) % cfg.GRADIENT_ACCUMULATION_STEPS != 0:
             optimizer.step()
             scheduler.step()
             optimizer.zero_grad()
             ema_model.update()

        epoch_loss = running_loss / len(train_dataset)
        train_f1 = f1_score(train_labels_list, train_preds_list, average='macro')
        
        # Validation (EMA ì ìš©)
        model.eval()
        val_preds_list, val_labels_list = [], []
        val_loss = 0.0
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc=f'Fold {fold} | Epoch {epoch+1}/{cfg.N_EPOCHS} (Val)'):
                images, labels = images.to(cfg.DEVICE), labels.to(cfg.DEVICE)
                
                ema_model.apply_shadow() 
                outputs = model(images)
                ema_model.apply_shadow(save_path=None) 
                
                loss = criterion(outputs, labels)
                
                val_loss += loss.item() * images.size(0)
                val_preds_list.extend(outputs.argmax(dim=1).cpu().numpy())
                val_labels_list.extend(labels.cpu().numpy())
        
        val_loss /= len(val_dataset)
        val_f1 = f1_score(val_labels_list, val_preds_list, average='macro')
        
        print(f"  [Result] Loss: {epoch_loss:.4f} / Val Loss: {val_loss:.4f} | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f} (Best: {best_f1:.4f})")
        
        if run:
            run.log({
                "Fold": fold, "Epoch": epoch, "LR": optimizer.param_groups[0]['lr'],
                "Train/Loss": epoch_loss, "Train/F1": train_f1,
                "Val/Loss": val_loss, "Val/F1": val_f1
            })
        
        if val_f1 > best_f1:
            best_f1 = val_f1
            patience_counter = 0
            ema_model.apply_shadow(save_path=model_path)
            print(f"  ğŸ† New Best F1: {best_f1:.4f}. EMA Model saved.")
        else:
            patience_counter += 1
            if patience_counter >= cfg.PATIENCE: # ğŸ”¥ PATIENCE 5
                print(f"  ğŸ›‘ Early stopping on Fold {fold} at Epoch {epoch+1}")
                break
                
    if run:
        run.finish()
    return best_f1, model_path

@torch.no_grad()
def ultimate_inference_ensemble(cfg):
    """TTAë¥¼ í†µí•©í•œ ì´ì¢… ëª¨ë¸ ì•™ìƒë¸” ì¶”ë¡  (TTA_SIZE=3)"""
    print('\n' + '='*70)
    print(f'ğŸš€ ìµœì¢… TTA í†µí•© ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘ (TTA Size: {cfg.TTA_SIZE})')
    print('='*70)

    test_df = pd.read_csv(f'{cfg.DATA_DIR}/sample_submission.csv')
    test_df = test_df.drop('target', axis=1, errors='ignore')
    
    all_model_paths = glob.glob(os.path.join(cfg.ENSEMBLE_MODEL_BASE_DIR, '*', 'best_model_fold_*.pth'))
    
    if not all_model_paths:
        print("âš ï¸ ê²½ê³ : ì•™ìƒë¸” í´ë”ì—ì„œ ëª¨ë¸ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ í•™ìŠµëœ 5ê°œ ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # ì´ ì½”ë“œ ì‹¤í–‰ ì§í›„ ì €ì¥ëœ ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì œí•œ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        all_model_paths = glob.glob(os.path.join(os.path.abspath('.'), '*', 'best_model_fold_*.pth'))
        if not all_model_paths:
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤.")

    print(f"ì•™ìƒë¸”ì— ì‚¬ìš©í•  ì´ ëª¨ë¸ ìˆ˜: {len(all_model_paths)}ê°œ")
    
    model_name_map = {
        'tf_efficientnet_b4_ns': 'tf_efficientnet_b4_ns', 
        'convnext_base.fb_in22k': 'convnext_base.fb_in22k_ft_in1k',
        'tf_efficientnetv2_l.in21k_ft_in1k': 'tf_efficientnetv2_l.in21k_ft_in1k',
    }
    
    all_logits = np.zeros((len(test_df), cfg.NUM_CLASSES), dtype=np.float32)
    
    for i, model_path in enumerate(tqdm(all_model_paths, desc="ì•™ìƒë¸” ì¶”ë¡  ì§„í–‰")):
        model_key = None
        for key in model_name_map:
            if key in model_path:
                model_key = key
                break
        
        if model_key is None:
            # ì´ì „ì— í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œì˜ ëª¨ë¸ ì´ë¦„ì„ ì°¾ì•„ Config.MODEL_NAMEìœ¼ë¡œ ëŒ€ì²´
            current_model = timm.create_model(cfg.MODEL_NAME, pretrained=False, num_classes=cfg.NUM_CLASSES)
        else:
            current_model = timm.create_model(model_name_map[model_key], pretrained=False, num_classes=cfg.NUM_CLASSES)
            
        current_model.load_state_dict(torch.load(model_path, map_location=cfg.DEVICE))
        current_model.to(cfg.DEVICE)
        current_model.eval()

        fold_logits_sum = np.zeros((len(test_df), cfg.NUM_CLASSES), dtype=np.float32)
        
        # ê¸°ë³¸ ì˜ˆì¸¡ (1íšŒ)
        test_dataset_base = DocumentDataset(test_df, f'{cfg.DATA_DIR}/test', get_transforms('val_base', cfg), is_test=True)
        test_loader_base = DataLoader(test_dataset_base, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)

        base_logits_list = []
        for images in test_loader_base:
            outputs = current_model(images.to(cfg.DEVICE))
            base_logits_list.append(outputs.cpu().numpy())
        fold_logits_sum += np.concatenate(base_logits_list, axis=0)
        
        # TTA ì ìš© ì˜ˆì¸¡ (TTA_SIZE íšŒ)
        for tta_iter in range(cfg.TTA_SIZE): # ğŸ”¥ TTA_SIZE 3
            test_dataset_tta = DocumentDataset(test_df, f'{cfg.DATA_DIR}/test', get_transforms('test', cfg), is_test=True)
            test_loader_tta = DataLoader(test_dataset_tta, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
            
            tta_logits_list = []
            for images in test_loader_tta:
                outputs = current_model(images.to(cfg.DEVICE))
                tta_logits_list.append(outputs.cpu().numpy())
            
            fold_logits_sum += np.concatenate(tta_logits_list, axis=0)

        # Logit í‰ê· : (ê¸°ë³¸ ì˜ˆì¸¡ 1íšŒ + TTA ì˜ˆì¸¡ TTA_SIZEíšŒ)
        fold_avg_logits = fold_logits_sum / (cfg.TTA_SIZE + 1)
        all_logits += fold_avg_logits
        
    avg_logits = all_logits / len(all_model_paths)
    predictions = np.argmax(avg_logits, axis=1)

    return test_df['ID'], predictions


# ==============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================

def main():
    cfg = Config()
    
    download_and_extract_data(cfg.DATA_DIR)
    
    TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
    EXP_DIR = f'./experiments/{cfg.MODEL_NAME}_{TIMESTAMP}'
    Path(EXP_DIR).mkdir(parents=True, exist_ok=True)
    print(f"ğŸ§ª ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„±: {EXP_DIR}")
    
    train_df = pd.read_csv(f'{cfg.DATA_DIR}/train.csv')
    train_labels = train_df['target'].values
    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)
    class_weights = torch.tensor(class_weights, dtype=torch.float32)
    print(f"âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: {class_weights.numpy().round(3)}")
    
    # K-Fold í•™ìŠµ 
    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=42)
    fold_results = []
    
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(train_df['ID'], train_df['target'])):
        train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)
        val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)
        
        fold_num = fold_idx + 1 
        
        best_f1, model_path = train_fold(fold_num, train_fold_df, val_fold_df, EXP_DIR, class_weights, cfg)
        
        fold_results.append({
            'fold': fold_num, 
            'f1': best_f1,
            'model_path': model_path
        })
    
    results_df = pd.DataFrame(fold_results)
    print(f'\n{"="*50}')
    print(f'ğŸ“Š V9 í•™ìŠµ ê²°ê³¼ ìš”ì•½ - ëª¨ë¸: {cfg.MODEL_NAME}')
    print(f'{"="*50}')
    print(results_df[['fold', 'f1']].to_markdown(index=False))
    print(f'\nğŸ“Œ CV í‰ê·  F1: {results_df["f1"].mean():.4f}')
    
    # 5. í…ŒìŠ¤íŠ¸ ì¶”ë¡  ë° ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± (ì•™ìƒë¸”)
    test_ids, predictions = ultimate_inference_ensemble(cfg)
    
    submission = pd.DataFrame({'ID': test_ids, 'target': predictions})
    
    submission_filename = f'submission_{TIMESTAMP}_PL_FIX_V9_CV{results_df["f1"].mean():.4f}.csv'
    submission_path = os.path.join(EXP_DIR, submission_filename)
    submission.to_csv(submission_path, index=False)
    
    total_models = len(glob.glob(os.path.join(cfg.ENSEMBLE_MODEL_BASE_DIR, '*', 'best_model_fold_*.pth')))
    
    print('\n' + '='*70)
    print("âœ¨ ìµœì¢… ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"ì•™ìƒë¸”ì— í¬í•¨ëœ ì „ì²´ ëª¨ë¸ ìˆ˜: {total_models}ê°œ")
    print(f"ìµœì¢… ì œì¶œ íŒŒì¼ ê²½ë¡œ: {submission_path}")
    print('='*70)

if __name__ == '__main__':
    main()