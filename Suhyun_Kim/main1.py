import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
from sklearn.utils.class_weight import compute_class_weight
import os
from datetime import datetime
from pathlib import Path
from PIL import Image
import urllib.request
import glob
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¹„í™œì„±í™”
warnings.filterwarnings("ignore", category=UserWarning)

# ==============================================================================
# 1. ì„¤ì • ë° í™˜ê²½
# ==============================================================================

# Augraphy ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
try:
    from augraphy import InkBleed, PaperFactory, DirtyDrum, Jpeg, Brightness, AugraphyPipeline
    AUGRAPHY_AVAILABLE = True
except ImportError:
    AUGRAPHY_AVAILABLE = False
    print("âš ï¸ Augraphy ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (pip install augraphy) - ë¬¸ì„œ íŠ¹í™” ì¦ê°• ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤.")

class Config:
    """ëª¨ë¸ ë° í•™ìŠµì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Vision Transformer, TTA ì ìš©)"""
    # ğŸ”¥ Vision Transformer ëª¨ë¸ë¡œ ë³€ê²½ (DINO ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜)
    MODEL_NAME = 'vit_base_patch16_224.dino' 
    NUM_CLASSES = 17
    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° 
    N_EPOCHS = 30 
    # ViTëŠ” 224x224 í•´ìƒë„ê°€ í‘œì¤€ì´ë©°, BATCH_SIZEë¥¼ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    BATCH_SIZE = 16 
    # ğŸ”¥ ViTì˜ í‘œì¤€ ì…ë ¥ í¬ê¸°ë¡œ ë³€ê²½
    IMAGE_SIZE = 224  
    LR = 3e-5 # ViTëŠ” ë‚®ì€ LRì´ ì•ˆì •ì 
    
    # ê²½ì‚¬ ëˆ„ì  ì„¤ì • (Effective Batch Size = 16 * 2 = 32 ìœ ì§€)
    GRADIENT_ACCUMULATION_STEPS = 2
    
    # ì •ê·œí™” ë° ìµœì í™”
    N_FOLDS = 5 
    WEIGHT_DECAY = 0.05
    LABEL_SMOOTHING = 0.05
    
    # ìŠ¤ì¼€ì¤„ëŸ¬
    SCHEDULER_T0 = 10
    SCHEDULER_TMULT = 2
    PATIENCE = 7 
    
    # ğŸ”¥ TTA(Test Time Augmentation) ì„¤ì •
    TTA_SIZE = 5 # TTA íšŸìˆ˜ (ì˜ˆ: ì›ë³¸, ì¢Œìš°ë°˜ì „, 5ê°€ì§€ í¬ë¡­/ì»¬ëŸ¬ jitter ë“±)
    
    # ê²½ë¡œ ë° ì¦ê°•
    DATA_DIR = 'data'
    AUG_STRATEGY = 'hybrid'


# ==============================================================================
# 2. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ë° í´ë˜ìŠ¤
# ==============================================================================

def download_and_extract_data(data_dir='data'):
    """ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ"""
    data_path = Path(data_dir)
    
    if data_path.exists() and (data_path / 'train.csv').exists():
        return
    
    print("="*70)
    print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„ ì¤‘...")
    print("="*70)
    
    DATA_URL = "https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000372/data/data.tar.gz"
    DATA_FILE = "data.tar.gz"
    
    try:
        urllib.request.urlretrieve(DATA_URL, DATA_FILE)
        import tarfile
        with tarfile.open(DATA_FILE, 'r:gz') as tar:
            tar.extractall('.')
        os.remove(DATA_FILE)
        
        print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\n")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

class DocumentDataset(Dataset):
    """ë¬¸ì„œ ì´ë¯¸ì§€ ë¡œë“œ ë° ë¼ë²¨ë§ì„ ìœ„í•œ PyTorch Dataset"""
    def __init__(self, df, img_dir, transform=None, is_test=False, is_tta=False):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.is_tta = is_tta # TTA ì‹œ True

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_id = self.df.iloc[idx]['ID']
        img_path = os.path.join(self.img_dir, img_id)
        
        image = Image.open(img_path).convert("RGB")
        image = np.array(image)

        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']

        if self.is_test:
            # TTA ì¶”ë¡  ì‹œ, ì´ë¯¸ì§€ëŠ” DataLoaderì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            return image
        else:
            label = self.df.iloc[idx]['target']
            return image, torch.tensor(label, dtype=torch.long)

def ensure_3_channels(image):
    """Augraphy í›„ 2Dë¡œ ë³€í™˜ë˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 3ì±„ë„(HxWx3)ì„ ê°•ì œí•©ë‹ˆë‹¤."""
    if image.ndim == 2:
        return np.repeat(image[:, :, np.newaxis], 3, axis=2)
    elif image.ndim == 3 and image.shape[-1] == 1:
        return np.repeat(image, 3, axis=-1)
    elif image.ndim == 3 and image.shape[-1] == 3:
        return image
    else:
        return image

def get_augraphy_pipeline(strategy='hybrid'):
    """ë¬¸ì„œ ì´ë¯¸ì§€ íŠ¹í™” ì¦ê°• íŒŒì´í”„ë¼ì¸"""
    if not AUGRAPHY_AVAILABLE:
        return None

    ink_p, paper_p, post_p = 0.7, 0.6, 0.5 

    ink_phase = [InkBleed(intensity_range=(0.05, 0.20), p=ink_p)]
    paper_phase = [PaperFactory(p=paper_p), DirtyDrum(p=paper_p * 0.7)]
    post_phase = [Jpeg(quality_range=(50, 95), p=post_p), Brightness(brightness_range=(0.8, 1.2), p=post_p)]

    return AugraphyPipeline(ink_phase=ink_phase, paper_phase=paper_phase, post_phase=post_phase)

# ğŸ”¥ TTA ì¶”ë¡ ì— ì‚¬ìš©ë  ë³€í™˜ í•¨ìˆ˜
def get_tta_transforms(cfg):
    return A.Compose([
        A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE),
        A.OneOf([
            A.HorizontalFlip(p=1.0),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=5, p=1.0),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=1.0),
            A.SafeRotate(limit=10, p=1.0)
        ], p=0.8), # TTA ë•Œ í•œ ê°€ì§€ ë³€í™˜ë§Œ ê°•í•˜ê²Œ ì ìš©
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

def get_transforms(stage, cfg):
    """Albumentations ë° Augraphyë¥¼ í†µí•©í•œ ì´ë¯¸ì§€ ë³€í™˜ íŒŒì´í”„ë¼ì¸"""
    augraphy_pipeline = get_augraphy_pipeline(cfg.AUG_STRATEGY)
    
    if stage == 'train':
        albu_list = [
            # ğŸ”¥ ViT í‘œì¤€ ì…ë ¥ í¬ê¸° 224x224ë¡œ ë³€ê²½
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE), 
            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, p=0.7),
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
            A.CLAHE(p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]
        
        if AUGRAPHY_AVAILABLE and augraphy_pipeline is not None:
            albu_list.insert(1, A.Lambda(
                image=lambda x, **kwargs: ensure_3_channels(augraphy_pipeline.augment(x)['output']), 
                p=1.0)
            )
            
        return A.Compose(albu_list)
    
    elif stage == 'val':
        return A.Compose([
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    
    # TTAë¥¼ ìœ„í•œ ê¸°ë³¸ ë³€í™˜ (Resize + Normalize)
    elif stage == 'test_base':
        return A.Compose([
            A.Resize(cfg.IMAGE_SIZE, cfg.IMAGE_SIZE),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    
    return None

# ==============================================================================
# 3. í•™ìŠµ ë° ì¶”ë¡  ë¡œì§
# ==============================================================================

def train_fold(fold, train_df, val_df, exp_dir, class_weights, cfg):
    """ë‹¨ì¼ Fold í•™ìŠµ ë° ìµœì  ëª¨ë¸ ì €ì¥ (ê²½ì‚¬ ëˆ„ì  ì ìš©)"""
    print(f'\n{"="*50}')
    print(f'âš¡ï¸ Fold {fold} í•™ìŠµ ì‹œì‘')
    print(f'{"="*50}')
    
    train_dataset = DocumentDataset(train_df, f'{cfg.DATA_DIR}/train', get_transforms('train', cfg))
    val_dataset = DocumentDataset(val_df, f'{cfg.DATA_DIR}/train', get_transforms('val', cfg))
    
    # BATCH_SIZE=16 ì‚¬ìš©
    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    
    # ğŸ”¥ ViT ëª¨ë¸ ë¡œë“œ
    model = timm.create_model(cfg.MODEL_NAME, pretrained=True, num_classes=cfg.NUM_CLASSES)
    model.to(cfg.DEVICE)

    criterion = nn.CrossEntropyLoss(weight=class_weights.to(cfg.DEVICE), 
                                    label_smoothing=cfg.LABEL_SMOOTHING)

    optimizer = optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)

    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=cfg.SCHEDULER_T0, T_mult=cfg.SCHEDULER_TMULT, eta_min=1e-7
    )
    
    best_f1 = 0.0
    patience_counter = 0
    model_path = os.path.join(exp_dir, f'best_model_fold_{fold}.pth')
    
    for epoch in range(cfg.N_EPOCHS):
        model.train()
        running_loss = 0.0
        train_preds_list, train_labels_list = [], []
        
        optimizer.zero_grad() 
        
        for step, (images, labels) in enumerate(tqdm(train_loader, desc=f'Fold {fold} | Epoch {epoch+1}/{cfg.N_EPOCHS} (Train)')):
            images, labels = images.to(cfg.DEVICE), labels.to(cfg.DEVICE)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            loss = loss / cfg.GRADIENT_ACCUMULATION_STEPS
            loss.backward()
            
            if (step + 1) % cfg.GRADIENT_ACCUMULATION_STEPS == 0:
                optimizer.step()
                scheduler.step(epoch + (step + 1) / len(train_loader)) 
                optimizer.zero_grad() 
            
            running_loss += loss.item() * images.size(0) * cfg.GRADIENT_ACCUMULATION_STEPS
            train_preds_list.extend(outputs.argmax(dim=1).cpu().numpy())
            train_labels_list.extend(labels.cpu().numpy())
        
        if (step + 1) % cfg.GRADIENT_ACCUMULATION_STEPS != 0:
             optimizer.step()
             optimizer.zero_grad()

        epoch_loss = running_loss / len(train_dataset)
        train_f1 = f1_score(train_labels_list, train_preds_list, average='macro')
        
        # Validation
        model.eval()
        val_preds_list, val_labels_list = [], []
        val_loss = 0.0
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc=f'Fold {fold} | Epoch {epoch+1}/{cfg.N_EPOCHS} (Val)'):
                images, labels = images.to(cfg.DEVICE), labels.to(cfg.DEVICE)
                outputs = model(images)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item() * images.size(0)
                val_preds_list.extend(outputs.argmax(dim=1).cpu().numpy())
                val_labels_list.extend(labels.cpu().numpy())
        
        val_loss /= len(val_dataset)
        val_f1 = f1_score(val_labels_list, val_preds_list, average='macro')
        
        print(f"  [Result] Loss: {epoch_loss:.4f} / Val Loss: {val_loss:.4f} | Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f} (Best: {best_f1:.4f})")
        
        if val_f1 > best_f1:
            best_f1 = val_f1
            patience_counter = 0
            torch.save(model.state_dict(), model_path)
            print(f"  ğŸ† New Best F1: {best_f1:.4f}. Model saved.")
        else:
            patience_counter += 1
            if patience_counter >= cfg.PATIENCE:
                print(f"  ğŸ›‘ Early stopping on Fold {fold} at Epoch {epoch+1}")
                break
                
    return best_f1, model_path

@torch.no_grad()
def inference_ensemble(exp_dir, cfg):
    """5-Fold í•™ìŠµ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ Logit í‰ê·  ì•™ìƒë¸” ì¶”ë¡  (TTA ì ìš©)"""
    print('\n' + '='*50)
    print(f'ğŸš€ 5-Fold ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘ (TTA: {cfg.TTA_SIZE}íšŒ ì ìš©)')
    print('='*50)

    test_df = pd.read_csv(f'{cfg.DATA_DIR}/sample_submission.csv')
    test_df = test_df.drop('target', axis=1, errors='ignore')
    
    # TTAë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ” ê¸°ë³¸ ì¶”ë¡  DataLoader
    test_dataset_base = DocumentDataset(test_df, f'{cfg.DATA_DIR}/test', get_transforms('test_base', cfg), is_test=True)
    test_loader_base = DataLoader(test_dataset_base, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    
    # TTAë¥¼ ìœ„í•œ ë³€í™˜ í•¨ìˆ˜
    tta_transforms = get_tta_transforms(cfg)

    model_paths = sorted(glob.glob(os.path.join(exp_dir, 'best_model_fold_*.pth')))
    if not model_paths:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ '{exp_dir}'ì—ì„œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•™ìŠµì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
        
    print(f"ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸ ìˆ˜: {len(model_paths)}ê°œ")

    all_logits = np.zeros((len(test_df), cfg.NUM_CLASSES), dtype=np.float32)
    
    for i, model_path in enumerate(model_paths):
        print(f"â–¶ï¸ ëª¨ë¸ {i+1}/{len(model_paths)} ì¶”ë¡  ì¤‘...")
        
        model = timm.create_model(cfg.MODEL_NAME, pretrained=False, num_classes=cfg.NUM_CLASSES)
        model.load_state_dict(torch.load(model_path, map_location=cfg.DEVICE))
        model.to(cfg.DEVICE)
        model.eval()
        
        fold_logits_sum = np.zeros((len(test_df), cfg.NUM_CLASSES), dtype=np.float32)
        
        # 1. TTAë¥¼ ì ìš©í•˜ì§€ ì•Šì€ ê¸°ë³¸ ì˜ˆì¸¡ (1íšŒ)
        base_logits_list = []
        for images in tqdm(test_loader_base, desc=f'Inference Model {i+1} (Base)'):
            images = images.to(cfg.DEVICE)
            outputs = model(images)
            base_logits_list.append(outputs.cpu().numpy())
        fold_logits_sum += np.concatenate(base_logits_list, axis=0)
        
        # 2. ğŸ”¥ TTA ì ìš© ì˜ˆì¸¡ (cfg.TTA_SIZE íšŒ)
        for tta_iter in range(cfg.TTA_SIZE):
            # TTAë¥¼ ìœ„í•œ ì„ì‹œ ë°ì´í„°ì…‹/ë¡œë” (TTA ë³€í™˜ì€ ëŸ°íƒ€ì„ì— ì ìš©)
            test_dataset_tta = DocumentDataset(test_df, f'{cfg.DATA_DIR}/test', tta_transforms, is_test=True, is_tta=True)
            test_loader_tta = DataLoader(test_dataset_tta, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
            
            tta_logits_list = []
            for images in tqdm(test_loader_tta, desc=f'Inference Model {i+1} (TTA {tta_iter+1}/{cfg.TTA_SIZE})'):
                images = images.to(cfg.DEVICE)
                outputs = model(images)
                tta_logits_list.append(outputs.cpu().numpy())
            
            fold_logits_sum += np.concatenate(tta_logits_list, axis=0)

        # Logit í‰ê· : (ê¸°ë³¸ ì˜ˆì¸¡ 1íšŒ + TTA ì˜ˆì¸¡ TTA_SIZEíšŒ)
        fold_avg_logits = fold_logits_sum / (cfg.TTA_SIZE + 1)
        all_logits += fold_avg_logits
        
    avg_logits = all_logits / len(model_paths)
    predictions = np.argmax(avg_logits, axis=1)

    return test_df['ID'], predictions


# ==============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================

def main():
    cfg = Config()
    
    # 1. ë°ì´í„° ì¤€ë¹„
    download_and_extract_data(cfg.DATA_DIR)
    
    # 2. ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì„¤ì •
    TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
    # ğŸ”¥ ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì´ë¦„ì— TTA í”Œë˜ê·¸ ì¶”ê°€
    EXP_DIR = f'./experiments/{cfg.MODEL_NAME}_tta{cfg.TTA_SIZE}_{TIMESTAMP}'
    Path(EXP_DIR).mkdir(parents=True, exist_ok=True)
    print(f"ğŸ§ª ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„±: {EXP_DIR}")
    
    # 3. ë°ì´í„° ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
    train_df = pd.read_csv(f'{cfg.DATA_DIR}/train.csv')
    train_labels = train_df['target'].values
    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)
    class_weights = torch.tensor(class_weights, dtype=torch.float32)
    print(f"âš–ï¸ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: {class_weights.numpy().round(3)}")
    
    # 4. K-Fold í•™ìŠµ
    skf = StratifiedKFold(n_splits=cfg.N_FOLDS, shuffle=True, random_state=42)
    fold_results = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df['ID'], train_df['target'])):
        train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)
        val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)
        
        best_f1, model_path = train_fold(fold, train_fold_df, val_fold_df, EXP_DIR, class_weights, cfg)
        
        fold_results.append({
            'fold': fold,
            'f1': best_f1,
            'model_path': model_path
        })
    
    # í•™ìŠµ ê²°ê³¼ ìš”ì•½
    results_df = pd.DataFrame(fold_results)
    print(f'\n{"="*50}')
    print('ğŸ“Š ìµœì¢… í•™ìŠµ ê²°ê³¼ ìš”ì•½')
    print(f'{"="*50}')
    print(results_df[['fold', 'f1']].to_markdown(index=False))
    print(f'\nğŸ“Œ CV í‰ê·  F1: {results_df["f1"].mean():.4f}')
    
    # 5. í…ŒìŠ¤íŠ¸ ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±
    # ì´ í•¨ìˆ˜ëŠ” TTAê°€ ì ìš©ë˜ì–´ ì¶”ë¡  ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    test_ids, predictions = inference_ensemble(EXP_DIR, cfg) 
    
    submission = pd.DataFrame({
        'ID': test_ids,
        'target': predictions
    })
    
    avg_f1 = results_df["f1"].mean()
    submission_filename = f'submission_{TIMESTAMP}_ensemble_tta{cfg.TTA_SIZE}_avgf1{avg_f1:.4f}.csv'
    submission_path = os.path.join(EXP_DIR, submission_filename)
    submission.to_csv(submission_path, index=False)
    
    print('\n' + '='*50)
    print("âœ¨ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
    print(f"ìµœì¢… ì œì¶œ íŒŒì¼ ê²½ë¡œ: {submission_path}")
    print('='*50)

if __name__ == '__main__':
    main()