# ========================================
# êµ¬ê¸€ ì½”ë©ìš© ë¬¸ì„œ ë¶„ë¥˜ í•™ìŠµ ì½”ë“œ
# í•œ ì…€ì—ì„œ ì „ì²´ ì‹¤í–‰ ê°€ëŠ¥
# ========================================

# ========== 0. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„ ==========
print("="*70)
print("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
print("="*70)

import os
import subprocess

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ
DATA_URL = "https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000372/data/data.tar.gz"
DATA_FILE = "/content/data.tar.gz"

if not os.path.exists("/content/data"):
    print(f"ğŸŒ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {DATA_URL}")
    subprocess.run(["wget", "-q", "--show-progress", DATA_URL, "-O", DATA_FILE], check=True)
    print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    
    print("\nğŸ“¦ ì••ì¶• í•´ì œ ì¤‘...")
    subprocess.run(["tar", "-xzf", DATA_FILE, "-C", "/content/"], check=True)
    print("âœ… ì••ì¶• í•´ì œ ì™„ë£Œ")
    
    # ì••ì¶• íŒŒì¼ ì‚­ì œ (ìš©ëŸ‰ ì ˆì•½)
    os.remove(DATA_FILE)
    print("ğŸ—‘ï¸  ì••ì¶• íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
    
    # ë°ì´í„° êµ¬ì¡° í™•ì¸
    print("\nğŸ“ ë°ì´í„° êµ¬ì¡°:")
    subprocess.run(["ls", "-lh", "/content/data/"])
    
    print("\nğŸ“· ì´ë¯¸ì§€ íŒŒì¼ ìƒ˜í”Œ:")
    result = subprocess.run(["ls", "/content/data/train/"], capture_output=True, text=True)
    train_files = result.stdout.split('\n')[:5]
    for f in train_files:
        if f:
            print(f"  - {f}")
    
    print(f"\nâœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
    print(f"   ê²½ë¡œ: /content/data/")
else:
    print("âœ… ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ê±´ë„ˆëœ€.")

print("="*70 + "\n")

# ========== 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ==========
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
import subprocess
import sys

print("ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
packages_to_install = [
    'timm',
    'albumentations',
    'augraphy'  # ë¬¸ì„œ íŠ¹í™” ì¦ê°• (ì„ íƒ)
]

for package in packages_to_install:
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])
        print(f"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ")
    except:
        print(f"âš ï¸  {package} ì„¤ì¹˜ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")

print("\nğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì¤‘...")
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
from sklearn.utils.class_weight import compute_class_weight
import os
from datetime import datetime
from pathlib import Path
from PIL import Image
import random
import zipfile

# Augraphy ì²´í¬
try:
    from augraphy import InkBleed, PaperFactory, DirtyDrum, Jpeg, Brightness, AugraphyPipeline
    AUGRAPHY_AVAILABLE = True
    print("âœ… Augraphy ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    AUGRAPHY_AVAILABLE = False
    print("âš ï¸  Augraphy ì—†ìŒ (Albumentationsë§Œ ì‚¬ìš©)")

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n")

# ========== 2. ì„¤ì • ==========
class Config:
    """í•™ìŠµ ì„¤ì • í´ë˜ìŠ¤"""
    def __init__(self):
        # ë°ì´í„° ê²½ë¡œ (ì½”ë©)
        self.DATA_DIR = '/content/data'
        self.TRAIN_DIR = '/content/data/train'
        self.TEST_DIR = '/content/data/test'
        
        # ëª¨ë¸ ì„¤ì •
        self.MODEL_NAME = 'tf_efficientnetv2_s'  # ë˜ëŠ” 'tf_efficientnetv2_m'
        self.IMG_SIZE = 384
        self.NUM_CLASSES = 17
        
        # í•™ìŠµ ì„¤ì • (ì½”ë© GPU ìµœì í™”)
        self.BATCH_SIZE = 16  # ì½”ë© GPUì— ë§ê²Œ ì¦ê°€
        self.ACCUMULATION_STEPS = 1  # GPU ì¶©ë¶„í•˜ë©´ ë¶ˆí•„ìš”
        self.EPOCHS = 15
        self.LR = 0.0001
        self.N_FOLDS = 5
        
        # ì •ê·œí™”
        self.DROPOUT_RATE = 0.4
        self.WEIGHT_DECAY = 0.01
        self.LABEL_SMOOTHING = 0.05
        self.PATIENCE = 3
        
        # ì¦ê°• ì„¤ì •
        self.AUG_STRATEGY = 'hybrid'  # 'albumentations', 'augraphy', 'hybrid'
        self.AUGRAPHY_STRENGTH = 'light'
        
        # ê¸°íƒ€
        self.USE_MIXUP = False
        self.MIXUP_ALPHA = 0.2
        self.USE_CLASS_WEIGHTS = True
        self.SEED = 42
        self.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
        
    def print_config(self):
        """ì„¤ì • ì¶œë ¥"""
        print('='*70)
        print('âš™ï¸  ì‹¤í—˜ ì„¤ì •')
        print('='*70)
        print(f'ëª¨ë¸: {self.MODEL_NAME}')
        print(f'ì´ë¯¸ì§€ í¬ê¸°: {self.IMG_SIZE}')
        print(f'ë°°ì¹˜ í¬ê¸°: {self.BATCH_SIZE}')
        print(f'ì—í­: {self.EPOCHS}, í•™ìŠµë¥ : {self.LR}')
        print(f'Fold ìˆ˜: {self.N_FOLDS}, Patience: {self.PATIENCE}')
        print(f'Dropout: {self.DROPOUT_RATE}, Weight Decay: {self.WEIGHT_DECAY}')
        print(f'ì¦ê°• ì „ëµ: {self.AUG_STRATEGY}')
        print(f'ë””ë°”ì´ìŠ¤: {self.DEVICE}')
        print('='*70)

config = Config()
TIMESTAMP = None

# ========== 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==========
def set_seed(seed=42):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

# ========== 4. ì¦ê°• í•¨ìˆ˜ë“¤ ==========
def get_albumentations_train(image_size):
    """ì¼ë°˜ ì´ë¯¸ì§€ìš© ì¦ê°•"""
    return A.Compose([
        A.Resize(image_size, image_size),
        A.Affine(translate_percent=0.03, scale=(0.95, 1.05), rotate=(-3, 3), p=0.3),
        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),
        A.GaussNoise(p=0.2),
        A.OneOf([
            A.GaussianBlur(blur_limit=(3, 5), p=1.0),
            A.MotionBlur(blur_limit=5, p=1.0),
        ], p=0.2),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

def get_augraphy_train(image_size):
    """ë¬¸ì„œ íŠ¹í™” ì¦ê°•"""
    if not AUGRAPHY_AVAILABLE:
        return get_albumentations_train(image_size)
    
    ink_phase = [InkBleed(intensity_range=(0.1, 0.3), p=0.2)]
    paper_phase = [PaperFactory(p=0.2), DirtyDrum(p=0.1)]
    post_phase = [Jpeg(quality_range=(60, 95), p=0.2), Brightness(brightness_range=(0.95, 1.05), p=0.2)]
    augraphy_pipeline = AugraphyPipeline(ink_phase, paper_phase, post_phase)
    
    def apply_augraphy_safe(image, **kwargs):
        result = augraphy_pipeline.augment(image)["output"]
        if len(result.shape) == 2:
            result = np.stack([result] * 3, axis=-1)
        elif result.shape[-1] == 1:
            result = np.repeat(result, 3, axis=-1)
        elif result.shape[-1] == 4:
            result = result[:, :, :3]
        return result
    
    return A.Compose([
        A.Lambda(image=apply_augraphy_safe),
        A.Resize(image_size, image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_hybrid_train(image_size, augraphy_strength='light'):
    """Augraphy + Albumentations í˜¼í•©"""
    if not AUGRAPHY_AVAILABLE:
        return get_albumentations_train(image_size)
    
    if augraphy_strength == 'light':
        ink_p, paper_p, post_p = 0.2, 0.2, 0.2
    elif augraphy_strength == 'medium':
        ink_p, paper_p, post_p = 0.4, 0.4, 0.3
    else:
        ink_p, paper_p, post_p = 0.6, 0.5, 0.4
    
    ink_phase = [InkBleed(intensity_range=(0.05, 0.15), p=ink_p)]
    paper_phase = [PaperFactory(p=paper_p), DirtyDrum(p=paper_p * 0.5)]
    post_phase = [Jpeg(quality_range=(70, 95), p=post_p), Brightness(brightness_range=(0.95, 1.05), p=post_p)]
    augraphy_pipeline = AugraphyPipeline(ink_phase, paper_phase, post_phase)
    
    def apply_augraphy_safe(image, **kwargs):
        result = augraphy_pipeline.augment(image)["output"]
        if len(result.shape) == 2:
            result = np.stack([result] * 3, axis=-1)
        elif result.shape[-1] == 1:
            result = np.repeat(result, 3, axis=-1)
        elif result.shape[-1] == 4:
            result = result[:, :, :3]
        return result
    
    return A.Compose([
        A.Lambda(image=apply_augraphy_safe),
        A.Rotate(limit=3, p=0.4),
        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.4),
        A.GaussNoise(p=0.2),
        A.Resize(image_size, image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_val_transform(image_size):
    """ê²€ì¦ìš© ë³€í™˜"""
    return A.Compose([
        A.Resize(image_size, image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

def get_train_transform(cfg):
    """Config ê¸°ë°˜ ì¦ê°• ì„ íƒ"""
    if cfg.AUG_STRATEGY == 'albumentations':
        return get_albumentations_train(cfg.IMG_SIZE)
    elif cfg.AUG_STRATEGY == 'augraphy':
        return get_augraphy_train(cfg.IMG_SIZE)
    elif cfg.AUG_STRATEGY == 'hybrid':
        return get_hybrid_train(cfg.IMG_SIZE, cfg.AUGRAPHY_STRENGTH)
    else:
        return get_albumentations_train(cfg.IMG_SIZE)

# ========== 5. ë°ì´í„°ì…‹ ==========
class DocumentDataset(Dataset):
    def __init__(self, df, img_dir, transform=None, is_test=False):
        self.df = df.reset_index(drop=True)
        self.img_dir = Path(img_dir)
        self.transform = transform
        self.is_test = is_test
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = self.img_dir / row['ID']
        
        try:
            image = Image.open(img_path).convert('RGB')
            image = np.array(image)
        except Exception as e:
            image = np.zeros((224, 224, 3), dtype=np.uint8)
        
        if self.transform:
            image = self.transform(image=image)['image']
        
        if self.is_test:
            return image
        else:
            label = row['label']
            return image, label

# ========== 6. í•™ìŠµ í•¨ìˆ˜ ==========
def train_epoch(model, loader, criterion, optimizer, scheduler, cfg):
    model.train()
    losses = []
    optimizer.zero_grad()
    
    for idx, (images, labels) in enumerate(tqdm(loader, desc='Train', leave=False)):
        images = images.to(cfg.DEVICE)
        labels = labels.to(cfg.DEVICE)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        loss = loss / cfg.ACCUMULATION_STEPS
        loss.backward()
        
        if (idx + 1) % cfg.ACCUMULATION_STEPS == 0 or (idx + 1) == len(loader):
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            optimizer.zero_grad()
        
        losses.append(loss.item() * cfg.ACCUMULATION_STEPS)
    
    scheduler.step()
    return np.mean(losses)

def validate(model, loader, cfg):
    model.eval()
    preds_list = []
    labels_list = []
    
    with torch.no_grad():
        for images, labels in tqdm(loader, desc='Val', leave=False):
            images = images.to(cfg.DEVICE)
            outputs = model(images)
            preds = outputs.argmax(dim=1)
            
            preds_list.extend(preds.cpu().numpy())
            labels_list.extend(labels.numpy())
    
    f1 = f1_score(labels_list, preds_list, average='macro')
    return f1

# ========== 7. í´ë“œ í•™ìŠµ ==========
def train_fold(fold, train_df, val_df, exp_dir, class_weights, cfg):
    print(f'\n{"="*50}')
    print(f'Fold {fold} í•™ìŠµ ì‹œì‘')
    print(f'{"="*50}')
    
    train_transform = get_train_transform(cfg)
    val_transform = get_val_transform(cfg.IMG_SIZE)
    
    train_dataset = DocumentDataset(train_df, cfg.TRAIN_DIR, train_transform)
    val_dataset = DocumentDataset(val_df, cfg.TRAIN_DIR, val_transform)
    
    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=2)
    
    model = timm.create_model(cfg.MODEL_NAME, pretrained=True, num_classes=cfg.NUM_CLASSES, drop_rate=cfg.DROPOUT_RATE)
    model = model.to(cfg.DEVICE)
    
    optimizer = optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)
    
    if cfg.USE_CLASS_WEIGHTS and class_weights is not None:
        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=cfg.LABEL_SMOOTHING)
    else:
        criterion = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING)
    
    best_f1 = 0
    best_model_state = None
    patience_counter = 0
    
    for epoch in range(cfg.EPOCHS):
        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, cfg)
        val_f1 = validate(model, val_loader, cfg)
        
        print(f'Epoch {epoch+1}/{cfg.EPOCHS} - Loss: {train_loss:.4f}, F1: {val_f1:.4f}')
        
        if val_f1 > best_f1:
            best_f1 = val_f1
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            print(f'âœ… Best F1: {best_f1:.4f}')
        else:
            patience_counter += 1
            print(f'â³ Patience: {patience_counter}/{cfg.PATIENCE}')
        
        if patience_counter >= cfg.PATIENCE:
            print(f'Early stopping at epoch {epoch+1}')
            break
    
    model_filename = f'{exp_dir}/models/fold{fold}_{TIMESTAMP}_f1{best_f1:.4f}.pth'
    torch.save(best_model_state, model_filename)
    
    return best_f1, model_filename

# ========== 8. ì•™ìƒë¸” ì¶”ë¡  ==========
def inference_ensemble(test_df, fold_info, cfg):
    print(f'\n{"="*50}')
    print(f'ì¶”ë¡  ì‹œì‘ (ëª¨ë¸ {len(fold_info)}ê°œ)')
    print(f'{"="*50}')
    
    test_transform = get_val_transform(cfg.IMG_SIZE)
    test_dataset = DocumentDataset(test_df, cfg.TEST_DIR, test_transform, is_test=True)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)
    
    models = []
    fold_f1s = []
    
    for fold, f1, model_path in fold_info:
        model = timm.create_model(cfg.MODEL_NAME, pretrained=False, num_classes=cfg.NUM_CLASSES)
        model.load_state_dict(torch.load(model_path, weights_only=False))
        model = model.to(cfg.DEVICE)
        model.eval()
        models.append(model)
        fold_f1s.append(f1)
        print(f'âœ… Fold {fold} (F1: {f1:.4f}) ë¡œë“œ')
    
    avg_f1 = np.mean(fold_f1s)
    weights = torch.tensor(fold_f1s, dtype=torch.float32)
    weights = weights / weights.sum()
    
    all_predictions = []
    
    for images in tqdm(test_loader, desc='Inference', leave=False):
        images = images.to(cfg.DEVICE)
        
        fold_preds = []
        for model in models:
            with torch.no_grad():
                pred = model(images)
            fold_preds.append(pred.cpu())
        
        fold_preds_tensor = torch.stack(fold_preds)
        weights_expanded = weights.unsqueeze(1).unsqueeze(2)
        ensemble_pred = (fold_preds_tensor * weights_expanded).sum(dim=0)
        final_class = ensemble_pred.argmax(dim=1).item()
        all_predictions.append(final_class)
    
    return all_predictions, avg_f1

# ========== 9. ì œì¶œ íŒŒì¼ ìƒì„± ==========
def create_submission(test_df, predictions, avg_f1, exp_dir):
    filename = f'{exp_dir}/submission_{TIMESTAMP}_f1{avg_f1:.4f}.csv'
    
    submission = pd.DataFrame({
        'ID': test_df['ID'],
        'target': predictions
    })
    
    submission.to_csv(filename, index=False)
    
    print(f'\n{"="*50}')
    print(f'ì œì¶œ íŒŒì¼: {filename}')
    print(f'{"="*50}')
    print(submission.head(10))
    print(f'\nì˜ˆì¸¡ ë¶„í¬:')
    print(submission['target'].value_counts().sort_index())
    
    return filename

# ========== 10. ë©”ì¸ ì‹¤í–‰ ==========
if __name__ == '__main__':
    # ì´ˆê¸°í™”
    TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')
    set_seed(config.SEED)
    
    # ì‹¤í—˜ í´ë”
    EXP_DIR = f'/content/experiments/exp_{TIMESTAMP}'
    os.makedirs(EXP_DIR, exist_ok=True)
    os.makedirs(f'{EXP_DIR}/models', exist_ok=True)
    
    print('\n'+'='*70)
    print('ğŸš€ ë¬¸ì„œ ë¶„ë¥˜ í•™ìŠµ ì‹œì‘ (êµ¬ê¸€ ì½”ë©)')
    print('='*70)
    config.print_config()
    
    # ë°ì´í„° ë¡œë“œ
    print(f'\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...')
    train_df = pd.read_csv(f'{config.DATA_DIR}/train.csv')
    train_df['label'] = train_df['target']
    
    print(f'í•™ìŠµ ë°ì´í„°: {len(train_df)}ì¥')
    print(f'í´ë˜ìŠ¤: {train_df["label"].nunique()}ê°œ')
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
    if config.USE_CLASS_WEIGHTS:
        class_weights = compute_class_weight(
            'balanced',
            classes=np.unique(train_df['label']),
            y=train_df['label']
        )
        class_weights = torch.FloatTensor(class_weights).to(config.DEVICE)
    else:
        class_weights = None
    
    # K-Fold í•™ìŠµ
    skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=42)
    fold_results = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label']), start=1):
        train_fold_df = train_df.iloc[train_idx]
        val_fold_df = train_df.iloc[val_idx]
        
        best_f1, model_path = train_fold(fold, train_fold_df, val_fold_df, EXP_DIR, class_weights, config)
        
        fold_results.append({
            'fold': fold,
            'f1': best_f1,
            'model_path': model_path
        })
    
    # ê²°ê³¼ ì¶œë ¥
    results_df = pd.DataFrame(fold_results)
    print(f'\n{"="*50}')
    print('ğŸ“Š í•™ìŠµ ê²°ê³¼')
    print(f'{"="*50}')
    print(results_df[['fold', 'f1']])
    print(f'\ní‰ê·  F1: {results_df["f1"].mean():.4f}')
    print(f'ìµœê³  F1: {results_df["f1"].max():.4f}')
    
    # ê²°ê³¼ ì €ì¥
    results_filename = f'{EXP_DIR}/fold_results_{TIMESTAMP}.csv'
    results_df.to_csv(results_filename, index=False)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    if os.path.exists(f'{config.DATA_DIR}/test.csv'):
        test_df = pd.read_csv(f'{config.DATA_DIR}/test.csv')
    else:
        test_df = pd.read_csv(f'{config.DATA_DIR}/sample_submission.csv')
        test_df = test_df.drop('target', axis=1)
    
    print(f'\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ì¥')
    
    # ì•™ìƒë¸” ì¶”ë¡ 
    fold_info = [
        (row['fold'], row['f1'], row['model_path'])
        for _, row in results_df.iterrows()
    ]
    
    predictions, avg_f1 = inference_ensemble(test_df, fold_info, config)
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission_filename = create_submission(test_df, predictions, avg_f1, EXP_DIR)
    
    # êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥ (ì„ íƒ)
    try:
        from google.colab import drive
        drive.mount('/content/drive')
        
        import shutil
        drive_exp_dir = f'/content/drive/MyDrive/document_classification_results/exp_{TIMESTAMP}'
        os.makedirs(drive_exp_dir, exist_ok=True)
        
        # ì œì¶œ íŒŒì¼ê³¼ ê²°ê³¼ íŒŒì¼ ë³µì‚¬
        shutil.copy(submission_filename, drive_exp_dir)
        shutil.copy(results_filename, drive_exp_dir)
        
        print(f'\nğŸ’¾ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥ë¨: {drive_exp_dir}')
        print(f'   - ì œì¶œ íŒŒì¼: submission_{TIMESTAMP}_f1{avg_f1:.4f}.csv')
        print(f'   - ê²°ê³¼ íŒŒì¼: fold_results_{TIMESTAMP}.csv')
        
        # ëª¨ë¸ íŒŒì¼ë„ ë°±ì—…í•˜ë ¤ë©´ (ìš©ëŸ‰ í¬ë¯€ë¡œ ì„ íƒ ì‚¬í•­)
        SAVE_MODELS_TO_DRIVE = False  # Trueë¡œ ë³€ê²½í•˜ë©´ ëª¨ë¸ë„ ë°±ì—…
        if SAVE_MODELS_TO_DRIVE:
            models_dir = f'{drive_exp_dir}/models'
            os.makedirs(models_dir, exist_ok=True)
            print(f'\nğŸ“¦ ëª¨ë¸ íŒŒì¼ ë°±ì—… ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)')
            for fold_info in fold_results:
                model_path = fold_info['model_path']
                shutil.copy(model_path, models_dir)
            print(f'âœ… ëª¨ë¸ íŒŒì¼ ë°±ì—… ì™„ë£Œ: {models_dir}')
        
    except Exception as e:
        print(f'\nâš ï¸  êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì €ì¥ ì‹¤íŒ¨: {e}')
        print('   ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.')
    
    print(f'\n{"="*70}')
    print('âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!')
    print(f'{"="*70}')
    print(f'ğŸ“ ê²°ê³¼ íŒŒì¼: {results_filename}')
    print(f'ğŸ“ ì œì¶œ íŒŒì¼: {submission_filename}')
    print(f'{"="*70}\n')